# American-Sign-Language-recognition

## Overview
This project aims to pioneer the use of Convolutional Neural Networks (CNNs) to enhance American Sign Language (ASL) recognition, which is crucial for individuals who are deaf or hard of hearing. By employing advanced pre-processing techniques like grayscale conversion and strategic frame selection, raw video data is meticulously prepared for analysis. The developed bespoke CNN architecture adeptly extracts salient features and accurately classifies ASL signs depicted in processed frames.

## Key Features
- Utilizes CNNs for ASL recognition.
- Advanced pre-processing techniques for raw video data.
- Bespoke CNN architecture for feature extraction and classification.
- Rigorous performance evaluation using established ASL image and video datasets.
- Metrics include accuracy and recognition rate for quantitative insights.

- ## Results
- Achieved accuracy: 98%
- Recognition rate: 95%
